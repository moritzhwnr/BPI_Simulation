{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488330dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pm4py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8a8e0a",
   "metadata": {},
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ec46fb",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d31f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Henri\\OneDrive - Universität zu Köln\\Dokumente\\TUM\\3. Semester\\BPTM Seminar\\.venv\\Lib\\site-packages\\pm4py\\utils.py:992: UserWarning: Install the optional requirement `rustxes` to import/export files faster.\n",
      "  warnings.warn(\"Install the optional requirement `rustxes` to import/export files faster.\")\n",
      "c:\\Users\\Henri\\OneDrive - Universität zu Köln\\Dokumente\\TUM\\3. Semester\\BPTM Seminar\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "parsing log, completed traces :: 100%|██████████| 31509/31509 [01:15<00:00, 418.25it/s]\n"
     ]
    }
   ],
   "source": [
    "log = pm4py.read_xes('./data/BPI Challenge 2017.xes/BPI Challenge 2017.xes', return_legacy_log_object=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ce60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_events = [\"A_Pending\", \"A_Cancelled\", \"A_Denied\"]\n",
    "\n",
    "pruned_log = pm4py.filter_event_attribute_values(\n",
    "    log,\n",
    "    attribute_key=\"concept:name\",\n",
    "    values=allowed_events,\n",
    "    level=\"case\",\n",
    "    retain=True\n",
    ")\n",
    "\n",
    "perc = 0.001\n",
    "filtered_log = pm4py.filter_variants_by_coverage_percentage(pruned_log, perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c4c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pm4py.convert_to_dataframe(filtered_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120b3993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Action</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>EventOrigin</th>\n",
       "      <th>EventID</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>case:LoanGoal</th>\n",
       "      <th>case:ApplicationType</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>case:RequestedAmount</th>\n",
       "      <th>FirstWithdrawalAmount</th>\n",
       "      <th>NumberOfTerms</th>\n",
       "      <th>Accepted</th>\n",
       "      <th>MonthlyCost</th>\n",
       "      <th>Selected</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>OfferedAmount</th>\n",
       "      <th>OfferID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Created</td>\n",
       "      <td>User_1</td>\n",
       "      <td>A_Create Application</td>\n",
       "      <td>Application</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>complete</td>\n",
       "      <td>2016-01-01 09:51:15.304000+00:00</td>\n",
       "      <td>Existing loan takeover</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>statechange</td>\n",
       "      <td>User_1</td>\n",
       "      <td>A_Submitted</td>\n",
       "      <td>Application</td>\n",
       "      <td>ApplState_1582051990</td>\n",
       "      <td>complete</td>\n",
       "      <td>2016-01-01 09:51:15.352000+00:00</td>\n",
       "      <td>Existing loan takeover</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Created</td>\n",
       "      <td>User_1</td>\n",
       "      <td>W_Handle leads</td>\n",
       "      <td>Workflow</td>\n",
       "      <td>Workitem_1298499574</td>\n",
       "      <td>schedule</td>\n",
       "      <td>2016-01-01 09:51:15.774000+00:00</td>\n",
       "      <td>Existing loan takeover</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deleted</td>\n",
       "      <td>User_1</td>\n",
       "      <td>W_Handle leads</td>\n",
       "      <td>Workflow</td>\n",
       "      <td>Workitem_1673366067</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>2016-01-01 09:52:36.392000+00:00</td>\n",
       "      <td>Existing loan takeover</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Created</td>\n",
       "      <td>User_1</td>\n",
       "      <td>W_Complete application</td>\n",
       "      <td>Workflow</td>\n",
       "      <td>Workitem_1493664571</td>\n",
       "      <td>schedule</td>\n",
       "      <td>2016-01-01 09:52:36.403000+00:00</td>\n",
       "      <td>Existing loan takeover</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Action org:resource            concept:name  EventOrigin  \\\n",
       "0      Created       User_1    A_Create Application  Application   \n",
       "1  statechange       User_1             A_Submitted  Application   \n",
       "2      Created       User_1          W_Handle leads     Workflow   \n",
       "3      Deleted       User_1          W_Handle leads     Workflow   \n",
       "4      Created       User_1  W_Complete application     Workflow   \n",
       "\n",
       "                 EventID lifecycle:transition  \\\n",
       "0  Application_652823628             complete   \n",
       "1   ApplState_1582051990             complete   \n",
       "2    Workitem_1298499574             schedule   \n",
       "3    Workitem_1673366067             withdraw   \n",
       "4    Workitem_1493664571             schedule   \n",
       "\n",
       "                    time:timestamp           case:LoanGoal  \\\n",
       "0 2016-01-01 09:51:15.304000+00:00  Existing loan takeover   \n",
       "1 2016-01-01 09:51:15.352000+00:00  Existing loan takeover   \n",
       "2 2016-01-01 09:51:15.774000+00:00  Existing loan takeover   \n",
       "3 2016-01-01 09:52:36.392000+00:00  Existing loan takeover   \n",
       "4 2016-01-01 09:52:36.403000+00:00  Existing loan takeover   \n",
       "\n",
       "  case:ApplicationType      case:concept:name  case:RequestedAmount  \\\n",
       "0           New credit  Application_652823628               20000.0   \n",
       "1           New credit  Application_652823628               20000.0   \n",
       "2           New credit  Application_652823628               20000.0   \n",
       "3           New credit  Application_652823628               20000.0   \n",
       "4           New credit  Application_652823628               20000.0   \n",
       "\n",
       "   FirstWithdrawalAmount  NumberOfTerms Accepted  MonthlyCost Selected  \\\n",
       "0                    NaN            NaN      NaN          NaN      NaN   \n",
       "1                    NaN            NaN      NaN          NaN      NaN   \n",
       "2                    NaN            NaN      NaN          NaN      NaN   \n",
       "3                    NaN            NaN      NaN          NaN      NaN   \n",
       "4                    NaN            NaN      NaN          NaN      NaN   \n",
       "\n",
       "   CreditScore  OfferedAmount OfferID  \n",
       "0          NaN            NaN     NaN  \n",
       "1          NaN            NaN     NaN  \n",
       "2          NaN            NaN     NaN  \n",
       "3          NaN            NaN     NaN  \n",
       "4          NaN            NaN     NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03224d64",
   "metadata": {},
   "source": [
    "#### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d50c3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time:timestamp'] = pd.to_datetime(df['time:timestamp'])\n",
    "df = df.sort_values(['case:concept:name', 'time:timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebebc6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sequence Length Statistics ---\n",
      "Min Length: 16\n",
      "Mean Length: 24.23\n",
      "Median: 24.0\n",
      "90th Percentile: 31.0\n",
      "95th Percentile: 35.0\n",
      "99th Percentile: 39.0\n",
      "Max Length: 40\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "case_lengths = df.groupby('case:concept:name').size()\n",
    "\n",
    "# 2. Print Statistics\n",
    "print(\"--- Sequence Length Statistics ---\")\n",
    "print(f\"Min Length: {case_lengths.min()}\")\n",
    "print(f\"Mean Length: {case_lengths.mean():.2f}\")\n",
    "print(f\"Median: {case_lengths.median()}\")\n",
    "print(f\"90th Percentile: {np.percentile(case_lengths, 90)}\")\n",
    "print(f\"95th Percentile: {np.percentile(case_lengths, 95)}\")\n",
    "print(f\"99th Percentile: {np.percentile(case_lengths, 99)}\")\n",
    "print(f\"Max Length: {case_lengths.max()}\")\n",
    "\n",
    "# 3. (Optional) Quick Histogram\n",
    "# This helps you visually see the \"long tail\"\n",
    "plt.hist(case_lengths, bins=50, range=(0, np.percentile(case_lengths, 99) * 1.5))\n",
    "plt.title(\"Distribution of Case Lengths\")\n",
    "plt.xlabel(\"Number of Activities\")\n",
    "plt.ylabel(\"Count of Cases\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76414b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTOFF_LIMIT = 50 # Replace this with your chosen number\n",
    "\n",
    "# 1. Identify valid case IDs\n",
    "valid_cases = case_lengths[case_lengths <= CUTOFF_LIMIT].index\n",
    "\n",
    "# 2. Filter the DataFrame\n",
    "# This keeps only rows belonging to short/normal cases\n",
    "df = df[df['case:concept:name'].isin(valid_cases)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5e5bbe",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17a8068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ActivityID'] = df['concept:name'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c278f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Case to calculate time differences relative to THAT case\n",
    "g = df.groupby('case:concept:name')\n",
    "\n",
    "# A. Delta Time (Time since previous step)\n",
    "# shift(1) gets the previous row's time. \n",
    "df['Prev_Time'] = g['time:timestamp'].shift(1)\n",
    "df['Delta_Time'] = (df['time:timestamp'] - df['Prev_Time']).dt.total_seconds().fillna(0)\n",
    "\n",
    "# B. Cumulative Time (Time since case start)\n",
    "df['Case_Start_Time'] = g['time:timestamp'].transform('min')\n",
    "df['Cumulative_Time'] = (df['time:timestamp'] - df['Case_Start_Time']).dt.total_seconds()\n",
    "\n",
    "\n",
    "\n",
    "# C. Normalize/Log Transform (CRITICAL for Neural Networks)\n",
    "# Raw seconds (e.g., 3600, 84000) are too large for LSTMs. Log squeezes them.\n",
    "df['Log_Delta'] = np.log1p(df['Delta_Time'])\n",
    "df['Log_Cumulative'] = np.log1p(df['Cumulative_Time'])\n",
    "df['log_loan_amount'] = np.log1p(df['case:RequestedAmount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82c5af",
   "metadata": {},
   "source": [
    "#### extract prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9f4cfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Prefixes...\n"
     ]
    }
   ],
   "source": [
    "# 1. GROUP BY CASE\n",
    "# We extract the full sequences first\n",
    "feature_cols = ['ActivityID', 'Log_Delta', 'Log_Cumulative', 'log_loan_amount']\n",
    "grouped = df.groupby('case:concept:name')\n",
    "\n",
    "X_samples = []\n",
    "y_samples = []\n",
    "\n",
    "print(\"Generating Prefixes...\")\n",
    "\n",
    "for case_id, group in grouped:\n",
    "    # Convert group to numpy array\n",
    "    # Shape: (Seq_Len, Features)\n",
    "    case_data = group[feature_cols].values\n",
    "    \n",
    "    # We need the NEXT step's duration as the target\n",
    "    # We use 'Log_Delta' as the target (Time since previous event)\n",
    "    # The target for step t is the Delta_Time of step t+1\n",
    "    next_step_durations = group['Log_Delta'].shift(-1).values\n",
    "    \n",
    "    # Iterate through the case to create prefixes\n",
    "    # We stop at len-1 because the last event has no \"next event\"\n",
    "    for i in range(len(case_data) - 1):\n",
    "        # INPUT: History from start (0) up to current step (i)\n",
    "        # Shape: (i+1, Features)\n",
    "        prefix = case_data[0 : i+1]\n",
    "        \n",
    "        # TARGET: The duration of the NEXT event (i+1)\n",
    "        target = next_step_durations[i]\n",
    "        \n",
    "        # Validation: skip if target is NaN (shouldn't happen with logic above)\n",
    "        if not np.isnan(target):\n",
    "            X_samples.append(torch.tensor(prefix, dtype=torch.float32))\n",
    "            y_samples.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8ccfff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training Samples: 205871\n",
      "X Shape: torch.Size([205871, 39, 4])\n"
     ]
    }
   ],
   "source": [
    "# 2. PAD SEQUENCES\n",
    "# Now we have a list of many variable-length prefixes\n",
    "X_tensor = pad_sequence(X_samples, batch_first=True, padding_value=0)\n",
    "y_tensor = torch.tensor(y_samples, dtype=torch.float32)\n",
    "\n",
    "print(f\"Total Training Samples: {len(y_samples)}\")\n",
    "print(f\"X Shape: {X_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5046d73b",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d30de",
   "metadata": {},
   "source": [
    "#### definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ecc3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 1. MODEL ARCHITECTURE\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "class LSTMFeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Extracts features from the sequence data.\n",
    "    Input: (Batch, Seq_Len, Input_Dim) -> Output: (Batch, Feature_Dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        if mask is None:\n",
    "            # If no mask, take the last step\n",
    "            features = lstm_out[:, -1, :]\n",
    "        else:\n",
    "            # If mask exists, take the last VALID step based on the mask\n",
    "            # mask sum gives length; minus 1 gives index. Clamp to 0 to be safe.\n",
    "            seq_lengths = mask.sum(dim=1).long() - 1\n",
    "            seq_lengths = seq_lengths.clamp(min=0)\n",
    "            \n",
    "            # Select the correct hidden state for each batch element\n",
    "            batch_indices = torch.arange(x.size(0), device=x.device)\n",
    "            features = lstm_out[batch_indices, seq_lengths, :]\n",
    "            \n",
    "        return self.linear(features)\n",
    "\n",
    "class GPLayer(gpytorch.models.ApproximateGP):\n",
    "    \"\"\"\n",
    "    The Gaussian Process Layer.\n",
    "    Input: (Batch, Feature_Dim) -> Output: MultivariateNormal\n",
    "    \"\"\"\n",
    "    def __init__(self, inducing_points, feature_dim):\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
    "            num_inducing_points=inducing_points.size(0)\n",
    "        )\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(ard_num_dims=feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "class DKLModel(nn.Module):\n",
    "    \"\"\"\n",
    "    The Deep Kernel Learning Wrapper.\n",
    "    Combines LSTM and GP into one forward pass.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_extractor, gp_layer):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.gp_layer = gp_layer\n",
    "        \n",
    "        # This scaler helps map LSTM outputs to the [-1, 1] range \n",
    "        # which stabilizes the GP training\n",
    "        self.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(-1., 1.)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        features = self.feature_extractor(x, mask)\n",
    "        features = self.scale_to_bounds(features)\n",
    "        res = self.gp_layer(features)\n",
    "        return res\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. DATA HANDLING\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "class ProcessDataset(Dataset):\n",
    "    def __init__(self, raw_sequences, targets):\n",
    "        self.data = raw_sequences\n",
    "        self.targets = targets\n",
    "        self.max_len = max([s.size(0) for s in self.data])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.data[idx]\n",
    "        target = self.targets[idx]\n",
    "        \n",
    "        # 1. Create Mask (1 for data, 0 for padding)\n",
    "        mask = torch.ones(self.max_len)\n",
    "        mask[seq.size(0):] = 0\n",
    "        \n",
    "        # 2. Pad Sequence\n",
    "        pad_size = self.max_len - seq.size(0)\n",
    "        if pad_size > 0:\n",
    "            pad = torch.zeros(pad_size, seq.size(1))\n",
    "            seq = torch.cat((seq, pad), dim=0)\n",
    "            \n",
    "        return seq, torch.tensor(target).float(), mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d65541",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de4042cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")  # Should print 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbbed003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Configuration ---\n",
      "Total Samples:      205871\n",
      "Batch Size:         32\n",
      "Batches per Epoch:  6434\n",
      "Total Epochs:       30\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/30 [00:00<?, ?epoch/s]C:\\Users\\Henri\\AppData\\Local\\Temp\\ipykernel_29456\\3695142226.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return seq, torch.tensor(target).float(), mask\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/30 [00:14<?, ?epoch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mprint\u001b[39m(batch_count)\n\u001b[32m     59\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m loss = -mll(output, batch_y)\n\u001b[32m     63\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Henri\\OneDrive - Universität zu Köln\\Dokumente\\TUM\\3. Semester\\BPTM Seminar\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Henri\\OneDrive - Universität zu Köln\\Dokumente\\TUM\\3. Semester\\BPTM Seminar\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mDKLModel.forward\u001b[39m\u001b[34m(self, x, mask)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask):\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m     features = \u001b[38;5;28mself\u001b[39m.scale_to_bounds(features)\n\u001b[32m     73\u001b[39m     res = \u001b[38;5;28mself\u001b[39m.gp_layer(features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Henri\\OneDrive - Universität zu Köln\\Dokumente\\TUM\\3. Semester\\BPTM Seminar\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Henri\\OneDrive - Universität zu Köln\\Dokumente\\TUM\\3. Semester\\BPTM Seminar\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mLSTMFeatureExtractor.forward\u001b[39m\u001b[34m(self, x, mask)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     lstm_out, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     19\u001b[39m         \u001b[38;5;66;03m# If no mask, take the last step\u001b[39;00m\n\u001b[32m     20\u001b[39m         features = lstm_out[:, -\u001b[32m1\u001b[39m, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Henri\\OneDrive - Universität zu Köln\\Dokumente\\TUM\\3. Semester\\BPTM Seminar\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Henri\\OneDrive - Universität zu Köln\\Dokumente\\TUM\\3. Semester\\BPTM Seminar\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Henri\\OneDrive - Universität zu Köln\\Dokumente\\TUM\\3. Semester\\BPTM Seminar\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1123\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1120\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1123\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1135\u001b[39m     result = _VF.lstm(\n\u001b[32m   1136\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1137\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1145\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- A. Data Setup ---\n",
    "dataset = ProcessDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# --- Pre-Flight Dashboard ---\n",
    "# Checks exactly how much work needs to be done before starting\n",
    "total_samples = len(dataset)\n",
    "batch_size = dataloader.batch_size\n",
    "num_batches = len(dataloader)\n",
    "\n",
    "print(f\"\\n--- Training Configuration ---\")\n",
    "print(f\"Total Samples:      {total_samples}\")\n",
    "print(f\"Batch Size:         {batch_size}\")\n",
    "print(f\"Batches per Epoch:  {num_batches}\")\n",
    "print(f\"Total Epochs:       30\")\n",
    "print(f\"------------------------------\\n\")\n",
    "\n",
    "# --- B. Initialize Model ---\n",
    "lstm_hidden = 16\n",
    "feature_dim = 2 \n",
    "num_inducing = 20\n",
    "input_dim = 4\n",
    "\n",
    "extractor = LSTMFeatureExtractor(input_dim, lstm_hidden, feature_dim)\n",
    "inducing_points = torch.randn(num_inducing, feature_dim)\n",
    "gp_layer = GPLayer(inducing_points, feature_dim)\n",
    "\n",
    "model = DKLModel(extractor, gp_layer)\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "# --- C. Setup Optimizer ---\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.feature_extractor.parameters()},\n",
    "    {'params': model.gp_layer.parameters()},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=0.01)\n",
    "\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model.gp_layer, num_data=len(dataset))\n",
    "\n",
    "# --- D. Training Loop ---\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# We use ONE progress bar for the Epochs because batches are too fast\n",
    "# This bar will show: \"Epoch 1/30 ... [ETA] ... loss=...\"\n",
    "epoch_pbar = tqdm(range(30), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "for epoch in epoch_pbar:\n",
    "    epoch_loss = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    # Inner loop over batches (No progress bar here to avoid flickering)\n",
    "    for batch_x, batch_y, batch_mask in dataloader:\n",
    "        batch_count += 1 \n",
    "        if batch_count % 1000 == 0:\n",
    "            print(batch_count)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(batch_x, mask=batch_mask)\n",
    "        loss = -mll(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Calculate average loss for this epoch\n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    \n",
    "    # Update the progress bar text with the loss\n",
    "    # This lets you see the loss dropping in real-time next to the bar\n",
    "    epoch_pbar.set_postfix({'Avg Loss': f'{avg_loss:.4f}'})\n",
    "\n",
    "print(\"Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b53082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 4. EVALUATION\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "print(\"\\nEvaluation (First 3 samples):\")\n",
    "# Test on the first batch from the loader\n",
    "test_x, test_y, test_mask = next(iter(dataloader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get distribution\n",
    "    observed_pred = likelihood(model(test_x, mask=test_mask))\n",
    "    \n",
    "    # Extract Mean and Confidence\n",
    "    pred_log_mean = observed_pred.mean\n",
    "    pred_log_var = observed_pred.variance\n",
    "    \n",
    "    # Convert Log-Time back to Real-Time\n",
    "    pred_time = torch.exp(pred_log_mean)\n",
    "    real_time = torch.exp(test_y)\n",
    "    \n",
    "    # Calculate Uncertainty (2 standard deviations)\n",
    "    # Note: Confidence intervals in log-space are asymmetric in real-space\n",
    "    lower_conf = torch.exp(pred_log_mean - 2 * torch.sqrt(pred_log_var))\n",
    "    upper_conf = torch.exp(pred_log_mean + 2 * torch.sqrt(pred_log_var))\n",
    "\n",
    "# Print results\n",
    "for i in range(3):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  Actual Time:    {real_time[i].item():.2f}\")\n",
    "    print(f\"  Predicted Time: {pred_time[i].item():.2f}\")\n",
    "    print(f\"  95% Conf Range: {lower_conf[i].item():.2f} - {upper_conf[i].item():.2f}\")\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
